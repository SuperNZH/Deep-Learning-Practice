{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2.2_fashion_mnist.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyN1N+cYUwXNNDK+M1Ow+L+h",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SuperNZH/Deep-Learning-Practice/blob/main/Dive%20in%20DL/2_2_fashion_mnist.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mreRnYVPR1Ze"
      },
      "source": [
        "# 导入需要的包"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rtOD0csPQ2Bh",
        "outputId": "44212a9d-036d-4a1d-a139-1882143b5e1a"
      },
      "source": [
        "# 更方便的实现SOFTMAX，使用pytorch本身的方法\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import init\n",
        "import numpy as np\n",
        "import sys\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "sys.path.append('/content/drive/MyDrive/Colab_Notebooks/Dive_in_ML')\n",
        "import d2lzh_pytorch as d2l"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aVmu979bR6jo"
      },
      "source": [
        "# 读取数据"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UJqwrfQQRrFX",
        "outputId": "333dab0e-363c-43d4-d094-f7e2d01d54c7"
      },
      "source": [
        "batch_size = 256\n",
        "train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yeYW-jrYSUvO"
      },
      "source": [
        "# 定义和初始化模型"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xus4UqRVSRIu"
      },
      "source": [
        "# 先定义net\n",
        "# softmax是一个全连接层\n",
        "\n",
        "num_inputs = 784\n",
        "num_outputs = 10\n",
        "\n",
        "class LinearNet(nn.Module):\n",
        "  def __init__(self, num_inputs, num_outputs):\n",
        "    super(LinearNet, self).__init__()\n",
        "    self.linear = nn.Linear(num_inputs, num_outputs)\n",
        "  def forward(self, x):\n",
        "    # 之所以这个地方要用view的原因，是因为传进来的x不是标准的二维格式\n",
        "    # view的后面那个-1是把三位数据降为二维\n",
        "    # 所以如果想直接linear(x)的话，在传x进去之前就要先把它的维度格式处理好\n",
        "    y = self.linear(x.view(x.shape[0], -1))\n",
        "    return y"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m24SaUKWXySv"
      },
      "source": [
        "# 实例化model\n",
        "net = LinearNet(num_inputs, num_outputs)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TiTxkMQEahQk",
        "outputId": "85b2125a-5fa0-4cfa-8f49-c1e2231e7088"
      },
      "source": [
        "# 初始化权重\n",
        "\n",
        "init.normal_(net.linear.weight, mean=0, std=0.01)\n",
        "init.constant_(net.linear.bias, val=0)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tSwxklD5aHk6"
      },
      "source": [
        "# 更加简略的创建model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Xbaba4NX21t",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "be3777a9-609a-4a32-df0b-988fddbb339e"
      },
      "source": [
        "'''\n",
        "\n",
        "class FlattenLayer(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(FlattenLayer, self).__init__()\n",
        "    def forward(self, x): # x shape: (batch, *, *, ...)\n",
        "        return x.view(x.shape[0], -1)\n",
        "\n",
        "'''"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n\\nclass FlattenLayer(nn.Module):\\n    def __init__(self):\\n        super(FlattenLayer, self).__init__()\\n    def forward(self, x): # x shape: (batch, *, *, ...)\\n        return x.view(x.shape[0], -1)\\n\\n'"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2CKUzU5maF6t",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "930e232e-f8f9-4bda-9584-e93dec8032a2"
      },
      "source": [
        "'''\n",
        "\n",
        "from collections import OrderedDict\n",
        "\n",
        "net = nn.Sequential(\n",
        "    # FlattenLayer(),\n",
        "    # nn.Linear(num_inputs, num_outputs)\n",
        "    OrderedDict([\n",
        "        ('flatten', FlattenLayer()),\n",
        "        ('linear', nn.Linear(num_inputs, num_outputs))\n",
        "    ])\n",
        ")\n",
        "\n",
        "'''"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\n\\nfrom collections import OrderedDict\\n\\nnet = nn.Sequential(\\n    # FlattenLayer(),\\n    # nn.Linear(num_inputs, num_outputs)\\n    OrderedDict([\\n        ('flatten', FlattenLayer()),\\n        ('linear', nn.Linear(num_inputs, num_outputs))\\n    ])\\n)\\n\\n\""
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qBjDFtAzbuo2"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lvrO9yBPbwIL"
      },
      "source": [
        "# SOFTMAX --> Cross-Entropy Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CowWFl6pb5-U"
      },
      "source": [
        "# 分开定义softmax和损失函数可能会造成数值不稳定，所以用pytorch内置的函数\n",
        "\n",
        "loss = nn.CrossEntropyLoss()"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2d2b6TmRcMgj"
      },
      "source": [
        "# Optimization 优化"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JyECpDnXcSZT"
      },
      "source": [
        "# 用学习率0.01来优化，gradient decent\n",
        "optimizer = torch.optim.SGD(net.parameters(), lr=0.01)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YATG-4Mbc6B0"
      },
      "source": [
        "# Model Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ep4qb-lUOPtK"
      },
      "source": [
        "def evaluate_accuracy(data_iter, net):\n",
        "    acc_sum, n = 0.0, 0\n",
        "    for X, y in data_iter:\n",
        "        acc_sum += (net(X).argmax(dim=1) == y).float().sum().item()\n",
        "        n += y.shape[0]\n",
        "    return acc_sum / n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aC6pSoRjdK-e"
      },
      "source": [
        "# training其实就是epochs循环的细节实现\n",
        "# 通过多次迭代模型参数，在每次迭代中，根据当前读取的小批量数据样本（特征X和标签y），通过调用backward反向函数计算小批量随机梯度，并调用优化算法sgd迭代模型参数。\n",
        "num_epochs = 10\n",
        "\n",
        "def train(net, train_iter, test_iter, loss, num_epochs, batch_size, params=None, lr=None, optimizer=None):\n",
        "  for epoch in range(num_epochs):\n",
        "    train_l_sum, train_acc_sum, n = 0.0, 0.0, 0\n",
        "    # 损失函数为什么要用sum这个地方的评论解释不错 https://zhuanlan.zhihu.com/p/427853673l 因为loss算出来是一个10x1的损失向量，sum()之后变成一个总损失，标量，bw只能传标量\n",
        "    for X, y in train_iter:\n",
        "      y_hat = net(X)\n",
        "      l = loss\n",
        "      l = loss(y_hat, y).sum()\n",
        "\n",
        "      # backward之前手动清空梯度的原因是 https://www.zhihu.com/question/303070254 简单来说是处于pytorch的设计原因，节省内存\n",
        "      if optimizer is not None:\n",
        "        optimizer.zero_grad()\n",
        "      elif params is not None and params[0].grad is not None:\n",
        "        for param in params:\n",
        "          param.grad.data.zero_()\n",
        "\n",
        "      l.backward() # 算梯度\n",
        "\n",
        "      #step()的作用就是会更新所有的参数\n",
        "      if optimizer is None:\n",
        "        d2l.sgd(params, lr, batch_size)\n",
        "      else:\n",
        "        optimizer.step()\n",
        "\n",
        "      train_l_sum += l.item()\n",
        "      train_acc_sum += (y_hat.argmax(dim=1) == y).sum().item()\n",
        "      n += y.shape[0]\n",
        "\n",
        "    test_acc = evaluate_accuracy(test_iter, net)\n",
        "    print('epoch %d, loss %.4f, train acc %.3f, test acc %.3f' % (epoch + 1, train_l_sum / n, train_acc_sum / n, test_acc))"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KUBsUGzktYf4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3323cb7c-9625-4705-f803-268629177633"
      },
      "source": [
        "train(net, train_iter, test_iter, loss, num_epochs, batch_size, None, None, optimizer)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1, loss 0.0053, train acc 0.643, test acc 0.679\n",
            "epoch 2, loss 0.0036, train acc 0.716, test acc 0.725\n",
            "epoch 3, loss 0.0031, train acc 0.750, test acc 0.746\n",
            "epoch 4, loss 0.0029, train acc 0.768, test acc 0.758\n",
            "epoch 5, loss 0.0028, train acc 0.780, test acc 0.770\n",
            "epoch 6, loss 0.0026, train acc 0.788, test acc 0.779\n",
            "epoch 7, loss 0.0026, train acc 0.795, test acc 0.783\n",
            "epoch 8, loss 0.0025, train acc 0.800, test acc 0.788\n",
            "epoch 9, loss 0.0024, train acc 0.804, test acc 0.790\n",
            "epoch 10, loss 0.0024, train acc 0.807, test acc 0.795\n"
          ]
        }
      ]
    }
  ]
}