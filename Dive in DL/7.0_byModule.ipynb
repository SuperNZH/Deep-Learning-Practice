{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "7.0_byModule.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMI8EUSHZIKxwT16RMun22Y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SuperNZH/Deep-Learning-Practice/blob/main/Dive%20in%20DL/7.0_byModule.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "wG2At_uQYud7"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 继承Module"
      ],
      "metadata": {
        "id": "Pj8qvbJjRkh2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MLP(nn.Module):\n",
        "  def __init__(self, **kwargs):\n",
        "    super(MLP, self).__init__(**kwargs)\n",
        "    self.hidden = nn.Linear(784, 256)\n",
        "    self.act = nn.ReLU() # act 是激活函数的意思\n",
        "    self.output = nn.Linear(256, 10)\n",
        "  # 定义前向运算，根据x计算返回所需要的模型输出\n",
        "  def forward(self, x):\n",
        "    a = self.act(self.hidden(x))\n",
        "    return self.output(a)\n",
        "\n",
        "# 不需要定义反向函数，是因为这个class里面系统会自动求梯度，然后自动生成反向传播的backward函数"
      ],
      "metadata": {
        "id": "LzmVpqPjfG_N"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = torch.rand(2,784)\n",
        "print(X)\n",
        "net = MLP()\n",
        "print(net)\n",
        "net(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ygqnuiv1mIpn",
        "outputId": "314025fc-0a98-4988-aa4a-27c86dea79a4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6184, 0.3753, 0.6375,  ..., 0.8479, 0.2358, 0.0512],\n",
            "        [0.4935, 0.1910, 0.4643,  ..., 0.6272, 0.8248, 0.0692]])\n",
            "MLP(\n",
            "  (hidden): Linear(in_features=784, out_features=256, bias=True)\n",
            "  (act): ReLU()\n",
            "  (output): Linear(in_features=256, out_features=10, bias=True)\n",
            ")\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.1700, -0.0665, -0.0794, -0.0259, -0.1163, -0.0185, -0.0291, -0.1015,\n",
              "         -0.1451,  0.1311],\n",
              "        [ 0.2767, -0.0254, -0.0215, -0.0054, -0.2143,  0.1079, -0.0250, -0.1032,\n",
              "          0.0278,  0.0299]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Module子类 --> Sequential类"
      ],
      "metadata": {
        "id": "_Mnk-LKmRoBE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 如果模型的前向计算为简单串联各个层的计算时，可以用Sequential来更简单的定义模型\n",
        "# 这个是Sequential大概的运行逻辑\n",
        "class MySequential(nn.Module):\n",
        "  from collections import OrderedDict\n",
        "  def __init__(self, *args):\n",
        "    super(MySequential, self).__init__()\n",
        "    if len(args) == 1 and isinstance(args[0], OrderedDict):\n",
        "      for key, module in args[0].items():\n",
        "        self.add_module(key, module)\n",
        "    else:\n",
        "      for idx, module in enumerate(args):\n",
        "        self.add_module(str(idx), module)\n",
        "\n",
        "  def forward(self, input):\n",
        "    for module in self._modules.values():\n",
        "      input = module(input)\n",
        "    return input"
      ],
      "metadata": {
        "id": "tnDiY19SRsdV"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net = MySequential(\n",
        "    nn.Linear(784, 256),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(256, 10)\n",
        ")\n",
        "\n",
        "print(net)\n",
        "net(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J_4tQ6IHYYlq",
        "outputId": "563672b7-1d72-4392-b19f-e9aca1ae191c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MySequential(\n",
            "  (0): Linear(in_features=784, out_features=256, bias=True)\n",
            "  (1): ReLU()\n",
            "  (2): Linear(in_features=256, out_features=10, bias=True)\n",
            ")\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.2311, -0.0846, -0.1451,  0.1224, -0.0441, -0.2211, -0.1441, -0.0295,\n",
              "          0.1228, -0.2471],\n",
              "        [ 0.2209, -0.1845, -0.2211, -0.0266, -0.1540, -0.1795, -0.2760,  0.0276,\n",
              "          0.2003, -0.1763]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Module子类 --> ModuleList类"
      ],
      "metadata": {
        "id": "3KTCy0fSYz6x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ModuleList 接受一个子模块的列表作为输入，像list一样可以append和extend\n",
        "\n",
        "net = nn.ModuleList([nn.Linear(784,256), nn.ReLU()])\n",
        "net.append(nn.Linear(256,10))\n",
        "print(net[-1])\n",
        "print(net)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iwZECg_KY4Bp",
        "outputId": "a99bbc44-7303-4350-8a11-32ba3c7d575b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Linear(in_features=256, out_features=10, bias=True)\n",
            "ModuleList(\n",
            "  (0): Linear(in_features=784, out_features=256, bias=True)\n",
            "  (1): ReLU()\n",
            "  (2): Linear(in_features=256, out_features=10, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Module子类 --> ModuleDict类"
      ],
      "metadata": {
        "id": "mqmtjWmMbIjp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "net = nn.ModuleDict({\n",
        "    'linear': nn.Linear(784,256),\n",
        "    'act': nn.ReLU(),\n",
        "})\n",
        "net['output'] = nn.Linear(256,10)\n",
        "print(net['linear'])\n",
        "print(net.output)\n",
        "print(net)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hx0a2tQnbM5B",
        "outputId": "62521cdc-cdf2-4855-c4e3-91a15eb7114c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Linear(in_features=784, out_features=256, bias=True)\n",
            "Linear(in_features=256, out_features=10, bias=True)\n",
            "ModuleDict(\n",
            "  (linear): Linear(in_features=784, out_features=256, bias=True)\n",
            "  (act): ReLU()\n",
            "  (output): Linear(in_features=256, out_features=10, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Module拓展"
      ],
      "metadata": {
        "id": "8aMmwDPXJMUE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FancyMLP(nn.Module):\n",
        "  def __init__(self, **kwargs):\n",
        "    super(FancyMLP, self).__init__(**kwargs)\n",
        "    self.rand_weight = torch.rand((20,20), requires_grad=False)\n",
        "    self.linear = nn.Linear(20,20)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.linear(x)\n",
        "    x = nn.functional.relu(torch.mm(x, self.rand_weight.data) + 1)\n",
        "    x = self.linear(x)\n",
        "    while x.norm().item() > 1:\n",
        "      x /= 2\n",
        "    if x.norm().item() < 0.8:\n",
        "      x *= 10\n",
        "    return x.sum()"
      ],
      "metadata": {
        "id": "R37HmP0tJOfj"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = torch.rand(2, 20)\n",
        "net = FancyMLP()\n",
        "print(net)\n",
        "net(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TVo2ExsnJQES",
        "outputId": "77ffb987-5925-4a13-862b-54cf0ffa42dd"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FancyMLP(\n",
            "  (linear): Linear(in_features=20, out_features=20, bias=True)\n",
            ")\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(-19.6512, grad_fn=<SumBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    }
  ]
}