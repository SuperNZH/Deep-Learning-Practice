{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "reuse.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMK6LKePsEPJZCFsUQ78WI/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SuperNZH/Deep-Learning-Practice/blob/main/Reuse_Function/reuse.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Reusable Functions for Machine Learning and Colab platform**\n",
        "\n",
        "This notebook will be used for record every useful reuseable function during my work and study"
      ],
      "metadata": {
        "id": "GeKB6vDKhp60"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Google Drive**"
      ],
      "metadata": {
        "id": "gZW98Rhxq1bs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Mount Drive**"
      ],
      "metadata": {
        "id": "yKRFjgf2svEK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "_cODhT2glwQl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Read data"
      ],
      "metadata": {
        "id": "Og6Z_judt9ch"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "7cPhrucm0Dfa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = '/content/drive/MyDrive/Colab_Notebooks/dataset/data.csv'\n",
        "data = pd.read_csv(path)"
      ],
      "metadata": {
        "id": "0yBpvO7-t-re"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## EDA"
      ],
      "metadata": {
        "id": "19zfnhGOrjXp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Seperate the variable with different types(Object and Num)"
      ],
      "metadata": {
        "id": "wgP6110CtGY5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "categorical = [var for var in data.columns if data[var].dtype == 'object']\n",
        "print('There are {} categorical variables\\n'.format(len(categorical)))\n",
        "print('The categorical variables are: ', categorical)\n",
        "\n",
        "numerical = [var for var in data.columns if data[var].dtype != 'object']"
      ],
      "metadata": {
        "id": "5TtPW_94tUMg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Display the frequency of variables"
      ],
      "metadata": {
        "id": "r-DMxoO3ubeQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for var in data:\n",
        "  print(data[var].value_counts())"
      ],
      "metadata": {
        "id": "U2FuwTZPuXjR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check the missing values"
      ],
      "metadata": {
        "id": "V6R9m_qYySBy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data.isnull().sum()\n",
        "\n",
        "data[categorical].isnull().sum()"
      ],
      "metadata": {
        "id": "4BivpB-RyUt1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check the percent of missing value in variables"
      ],
      "metadata": {
        "id": "oDsqIdMDzK3q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# output the percentage of missing values in the numerical variables in training set\n",
        "for var in numerical:\n",
        "  if X_train[var].isnull().mean()>0:\n",
        "    print(var, (round(X_train[var].isnull().mean(), 4))*100, \"%\")"
      ],
      "metadata": {
        "id": "cc3hhV63zLsi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check the Cardinality"
      ],
      "metadata": {
        "id": "V9nUB3ogvER5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for var in categorical:\n",
        "  print(var, \" contains \", len(data[var].unique()), \" different labels\")"
      ],
      "metadata": {
        "id": "im6jmiKTvIVd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Split dataset"
      ],
      "metadata": {
        "id": "kndjm_pGyu4b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Seperate the X and y\n",
        "X = data.drop(['target_var'], axis = 1)\n",
        "y = data['target_var']\n",
        "\n",
        "# Train, test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n",
        "print(\"The Data Size: \", X_train.shape, X_test.shape)"
      ],
      "metadata": {
        "id": "V19L7TInyxyP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Engineering"
      ],
      "metadata": {
        "id": "ou39-r1OzhqR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Parse the Datetime format data"
      ],
      "metadata": {
        "id": "Sojulj3rvjaB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data['Date'] = pd.to_datetime(data['Date'])\n",
        "data['Year'] = data['Date'].dt.year\n",
        "data['Month'] = data['Date'].dt.month\n",
        "data['Day'] = data['Date'].dt.day\n",
        "data.drop('Date', axis = 1, inplace = True)"
      ],
      "metadata": {
        "id": "WcDfmGXtwQhK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Impute missing categorical variables with most frequent values"
      ],
      "metadata": {
        "id": "_W3HubrsznZ7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for feature in [X_train, X_test]:\n",
        "  feature['WindGustDir'].fillna(X_train['WindGustDir'].mode()[0], inplace=True)\n",
        "  feature['WindDir9am'].fillna(X_train['WindDir9am'].mode()[0], inplace=True)\n",
        "  feature['WindDir3pm'].fillna(X_train['WindDir3pm'].mode()[0], inplace=True)\n",
        "  feature['RainToday'].fillna(X_train['RainToday'].mode()[0], inplace=True)"
      ],
      "metadata": {
        "id": "IQNB2HRCzxAL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Drop columns with missing values"
      ],
      "metadata": {
        "id": "MTcSWSlBl5V1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Simplest but more potential problems\n",
        "cols_with_missing = [col for col in data.columns \n",
        "                     if data[col].isnull().any()] \n",
        "data.drop(cols_with_missing, axis=1, inplace=True)\n",
        "data.drop(cols_with_missing, axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "bL72JSxZmAPc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Process categorical variables"
      ],
      "metadata": {
        "id": "gGzeLIgvhoPD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Ordinal encoding"
      ],
      "metadata": {
        "id": "bGO3X3sIh2DT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "\n",
        "# make a copy\n",
        "label_X_train = X_train.copy()\n",
        "label_X_valid = X_valid.copy()\n",
        "\n",
        "# Apply ordinal encoder to each column with categorical data\n",
        "ordinal_encoder = OrdinalEncoder()\n",
        "label_X_train[object_cols] = ordinal_encoder.fit_transform(X_train[object_cols])\n",
        "label_X_valid[object_cols] = ordinal_encoder.transform(X_valid[object_cols])"
      ],
      "metadata": {
        "id": "EIyd45GGqxR8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### One hot encoding(Nominal variable)"
      ],
      "metadata": {
        "id": "SYIm4buKiKtb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "# Apply one-hot encoder to each column with categorical data\n",
        "OH_encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
        "OH_cols_train = pd.DataFrame(OH_encoder.fit_transform(X_train[object_cols]))\n",
        "OH_cols_valid = pd.DataFrame(OH_encoder.transform(X_valid[object_cols]))\n",
        "\n",
        "# One-hot encoding removed index; put it back\n",
        "OH_cols_train.index = X_train.index\n",
        "OH_cols_valid.index = X_valid.index\n",
        "\n",
        "# Remove categorical columns (will replace with one-hot encoding)\n",
        "num_X_train = X_train.drop(object_cols, axis=1)\n",
        "num_X_valid = X_valid.drop(object_cols, axis=1)\n",
        "\n",
        "# Add one-hot encoded columns to numerical features\n",
        "OH_X_train = pd.concat([num_X_train, OH_cols_train], axis=1)\n",
        "OH_X_valid = pd.concat([num_X_valid, OH_cols_valid], axis=1)"
      ],
      "metadata": {
        "id": "0eBviEP-rfVy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Can also use Pandas get_dummies() to transfer\n",
        "\n",
        "OH_cols_train = pd.get_dummies(X_train['X1'], prefix='Bla')\n",
        "OH_cols_test = pd.get_dummies(X_test['X1'], prefix='Bla')\n",
        "\n",
        "X_train = pd.concat([X_train, OH_cols_train], axis=1)\n",
        "X_test = pd.concat([X_test, OH_cols_test], axis=1)\n",
        "\n",
        "X_train.drop('X1', axis=1, inplace=True)\n",
        "X_test.drop('X1', axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "tJVP7IvZvTYI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}